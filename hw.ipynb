{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangjiarui/miniconda3/envs/ml/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import evaluate as evaluate\n",
    "from transformers import get_scheduler\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import argparse\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset boolq (/Users/wangjiarui/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afc68f0d4daa4c51b82ac1f7124da978"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b12cd0f71c945119684eed02ddd30f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1122b970a6674525bbe27b26f2105861"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e338fdde1a804c90abe0b2d934b19b6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce8e796d481d4b3db1af4ade72a826c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "dataset = load_dataset(\"boolq\")\n",
    "dataset = dataset.shuffle()  # shuffle the data\n",
    "\n",
    "dataset_train_subset = dataset['train'][:10]\n",
    "dataset_dev_subset = dataset['train'][:10]\n",
    "dataset_test_subset = dataset['train'][:10]\n",
    "mytokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class BoolQADataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for the dataset of BoolQ questions and answers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, passages, questions, answers, tokenizer, max_len):\n",
    "        self.passages = passages\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answers)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        This function is called by the DataLoader to get an instance of the data\n",
    "        :param index:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        passage = str(self.passages[index])\n",
    "        question = self.questions[index]\n",
    "        answer = self.answers[index]\n",
    "\n",
    "        # this is input encoding for your model. Note, question comes first since we are doing question answering\n",
    "        # and we don't wnt it to be truncated if the passage is too long\n",
    "        input_encoding = question + \" [SEP] \" + passage\n",
    "\n",
    "        # encode_plus will encode the input and return a dictionary of tensors\n",
    "        encoded_review = self.tokenizer.encode_plus(\n",
    "            input_encoding,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_review['input_ids'][0],  # we only have one example in the batch\n",
    "            'attention_mask': encoded_review['attention_mask'][0],\n",
    "            # attention mask tells the model where tokens are padding\n",
    "            'labels': torch.tensor(answer, dtype=torch.long)  # labels are the answers (yes/no)\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_dataset = BoolQADataset(\n",
    "        passages=list(dataset_train_subset['passage']),\n",
    "        questions=list(dataset_train_subset['question']),\n",
    "        answers=list(dataset_train_subset['answer']),\n",
    "        tokenizer=mytokenizer,\n",
    "        max_len=128\n",
    "    )\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "torch.Size([2, 128]) <class 'torch.Tensor'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
